{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主要内容\n",
    "\n",
    "1. Semantic Kernel 的特点和基本用法\n",
    "2. 了解 Semantic Kernel 内置的工具\n",
    "3. 如何用好 SDK 简化基于 LLM 的应用开发\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、大语言模型开发框架的价值是什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有开发框架（SDK）的核心价值，都是降低开发、维护成本。\n",
    "\n",
    "大语言模型开发框架的价值，是让开发者可以更方便地开发基于大语言模型的应用。主要提供两类帮助：\n",
    "\n",
    "1. 第三方能力抽象。比如 LLM、向量数据库、搜索引擎等\n",
    "2. 常用工具、方案封装\n",
    "3. 底层实现封装。比如流式接口、超时重连、异步与并行等\n",
    "\n",
    "好的开发框架，需要具备以下特点：\n",
    "\n",
    "1. 可靠性、鲁棒性\n",
    "2. 可维护性高\n",
    "3. 高内聚、低耦合\n",
    "4. 易用\n",
    "\n",
    "举些通俗的例子：\n",
    "\n",
    "- 与外部功能解依赖\n",
    "    - 比如可以随意更换 LLM 而不用大量重构代码\n",
    "    - 更换三方工具也同理\n",
    "- 经常变的部分要在外部维护而不是放在代码里\n",
    "    - 比如 Prompt 模板\n",
    "- 各种环境下都适用\n",
    "    - 比如线程安全\n",
    "- 方便调试和测试\n",
    "    - 至少要能感觉到用了比不用方便吧\n",
    "    - 合法的输入不会引发框架内部的报错\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>选对了框架，事半功倍；反之，事倍功半。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、Semantic Kernel\n",
    "\n",
    "「 Semantic Kernel (SK) is a lightweight SDK that lets you easily mix conventional programming languages with the latest in Large Language Model (LLM) AI \"prompts\" with templating, chaining, and planning capabilities out-of-the-box. 」\n",
    "\n",
    "1. Semantic Kernel 是微软研发的一个开源的，面向大模型的开发框架（SDK）；\n",
    "2. 它支持你用不同开发语言（C#/Python/Java）基于 OpenAI API/Azure OpenAI API/Huggingface 开发大模型应用；\n",
    "3. 它封装了一系列开箱即用的工具，包括：提示词模板、链式调用、规划能力等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SDK：Software Development Kit，它是一组软件工具和资源的集合，旨在帮助开发者创建、测试、部署和维护应用程序或软件。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1、SK 的开发进展\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Kernel 现在还是未正式发版状态。1.0.0 版预计今年底发布。\n",
    "\n",
    "1. C# 版最成熟，已开始 1.0.0-beta8：https://github.com/microsoft/semantic-kernel\n",
    "2. Python 版还在 dev 状态，但可用：https://github.com/microsoft/semantic-kernel\n",
    "3. Java 版 alpha 阶段：https://github.com/microsoft/semantic-kernel/tree/experimental-java\n",
    "4. TypeScript 版……，已经放弃了：https://github.com/microsoft/semantic-kernel/tree/experimental-typescript\n",
    "5. 文档写得特别好，但追不上代码更新速度：\n",
    "   - 更多讲解：https://learn.microsoft.com/en-us/semantic-kernel/overview/\n",
    "   - 更偏实操：https://github.com/microsoft/semantic-kernel/blob/main/samples/notebooks/python/00-getting-started.ipynb\n",
    "6. 更多生态：https://github.com/geffzhang/awesome-semantickernel\n",
    "\n",
    "这里可以了解最新进展：https://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages\n",
    "\n",
    "不同语言之间的概念都是相通的。本课程以 Python 版为例。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2、SK 的生态位\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与 LangChain 完全重叠。微软将此技术栈命名为 Copilot Stack。\n",
    "\n",
    "<img src=\"./picture/copilot-stack.png\" alt=\"SK 的生态位\" width=\"400\"/>\n",
    "\n",
    "解释：\n",
    "\n",
    "- Plugin extensibility: 插件扩展\n",
    "- Copilots: AI 助手（副驾驶），例如 GitHub Copilot、Office 365 Copilot、Windows Copilot\n",
    "- AI orchestration: AI 编排，SK 就在这里\n",
    "- Foundation models: 基础大模型，例如 GPT-4\n",
    "- AI infrastructure: AI 基础设施，例如 PyTorch、GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 怎么理解这个 **AI编排**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 是个野心勃勃的项目，它希望：\n",
    "\n",
    "1. 让开发者更容易的把LLM的能力集成到应用中，像调用函数一样简单\n",
    "2. 让开发者开发的LLM能力与应用解耦，高度可复用\n",
    "3. 让开发者能与微软的整个 Copilot 生态紧密结合，互相提供养料\n",
    "\n",
    "请带着这个视角，逐步体会后面所讲的知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3、SK 基础架构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./picture/mind-and-body-of-semantic-kernel.png\" alt=\"SK 的架构\" width=\"400\"/>\n",
    "\n",
    "解释：\n",
    "\n",
    "- Models and Memory: 类比为大脑\n",
    "- Connectors: 用来连接各种外部服务，类似驱动程序\n",
    "- Plugins: 用来连接内部技能\n",
    "- Triggers and actions: 外部系统的触发器和动作，类比为四肢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**类比：** Semantic Kernel 用 **Kernel** 命名，是因为它确实像个操作系统 kernel，做核心资源调配，各种资源都可以挂在它上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**说明：** Sematic Kernel 通过 **Kernel** 链接 LLM 与 **Functions**（功能）: \n",
    "  - Semantic Functions：通过 Prompt 实现的 LLM 能力\n",
    "  - Native Functions: 编程语言原生的函数功能 \n",
    "\n",
    "在 SK 中，一组 Function 组成一个技能（Skill/Plugin）。要运行 Skill/Plugin，需要有一个配置和管理的单元，这个组织管理单元就是 Kernel。\n",
    "\n",
    "Kernel 负责管理底层接口与调用顺序，例如：OpenAI/Azure OpenAI的授权信息、默认的LLM模型选择、对话上下文、技能参数的传递等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、环境搭建\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 安装 Python 3.x：https://www.python.org/downloads/\n",
    "2. 安装 SK 包：`pip install semantic-kernel`\n",
    "3. 在项目目录创建 .env 文件，添加以下内容：\n",
    "\n",
    "```bash\n",
    "# .env\n",
    "OPENAI_API_KEY=\"\"\n",
    "OPENAI_API_BASE=\"\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"\"\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "```\n",
    "\n",
    "OpenAI 和 Azure，配置好一个就行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>\n",
    "<ol>\n",
    "<li>由于 OpenAI 版本最近升级的原因，在实验室运行 `semantic-kernel`课件，需要降低<b> OpenAI </b>版本和重启内核</li>\n",
    "<li>执行  <b>%pip install openai==0.28</b></li>\n",
    "<li>在运行所有代码前，务必运行下面命令后，还需要重启内核 </li>\n",
    "</ol>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai==0.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![重启内核](./picture/restart-kernel.png) -->\n",
    "#### 重启内核\n",
    "\n",
    "<img src=\"./picture/restart-kernel.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1、Hello, World!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个简单示例。\n",
    "\n",
    "第一段代码是初始化。后面所有代码都要在执行过这段代码后，才能执行。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x7f587458fd10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_BASE_URL')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-3.5-turbo\", \n",
    "    api_key, \n",
    "    endpoint=endpoint\n",
    ")\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt3\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行讲笑话的 prompt。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好的，这是一个关于Hello world的笑话：\n",
      "\n",
      "程序员A对程序员B说：“我刚刚写了一个非常简单的Hello world程序。”\n",
      "程序员B问：“真的吗？那你能不能把它运行起来？”\n",
      "程序员A回答：“当然可以！”\n",
      "程序员B疑惑地问：“那你为什么不运行它呢？”\n",
      "程序员A笑着说：“因为我还没写完它的文档！”\n"
     ]
    }
   ],
   "source": [
    "# 定义 semantic function\n",
    "# 参数由{{ }}标识\n",
    "tell_joke_about = kernel.create_semantic_function(\"给我讲个关于{{$input}}的笑话吧\")\n",
    "\n",
    "# 运行 function 看结果\n",
    "result = await kernel.run_async(\n",
    "    tell_joke_about,\n",
    "    input_str=\"Hello world\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "用我们熟悉的操作系统来类比，可以更好地理解 SK。\n",
    "<ol>\n",
    "<li>启动操作系统：<code>kernel = sk.Kernel()</code></li>\n",
    "<li>安装驱动程序：<code>kernel.add_xxx_service()</code></li>\n",
    "<li>安装应用程序：<code>func = kernel.create_semantic_function()</code></li>\n",
    "<li>运行应用程序：<code>func()</code></li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "基于 SK 开发的主要工作是写「应用程序」，也就是 Plugins 也叫 Skills（见下文）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2、Semantic Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Functions 是纯用数据（Prompt + 配置文件）定义的，不需要编写任何代码。所以它与编程语言无关，可以被任何编程语言调用。\n",
    "\n",
    "一个典型的 semantic function 包含两个文件：\n",
    "\n",
    "- skprompt.txt: 存放 prompt，可以包含参数，还可以调用其它函数\n",
    "- config.json: 存放配置，包括函数功能，参数的数据类型，以及调用大模型时的参数\n",
    "\n",
    "举例：根据用户的自然语言指示，生成 Linux 命令\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1、skprompt.txt\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "将用户的指令转换成 Linux 命令\n",
    "只输出命令本身，不要分析，不要评论。\n",
    "\n",
    "{{$input}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2、config.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'schema': 1,\n",
       " 'type': 'completion',\n",
       " 'description': '将用户的指令转换成 Linux 命令',\n",
       " 'completion': {'max_tokens': 256,\n",
       "  'temperature': 0,\n",
       "  'top_p': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'frequency_penalty': 0},\n",
       " 'input': {'parameters': [{'name': 'input',\n",
       "    'description': '用户的指令',\n",
       "    'defaultValue': ''}]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"schema\": 1,\n",
    "    \"type\": \"completion\",\n",
    "    \"description\": \"将用户的指令转换成 Linux 命令\",\n",
    "    \"completion\": {\n",
    "        \"max_tokens\": 256,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"description\": \"用户的指令\",\n",
    "                \"defaultValue\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：\n",
    "\n",
    "- `type` 只有 `\"completion\"` 和 `\"embedding\"` 两种\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面两个文件都在 [sk_samples/SamplePlugin/GenerateCommand](sk_samples/SamplePlugin/GenerateCommand/) 目录下。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3、调用 Semantic Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date -s \"2023-04-01\"\n"
     ]
    }
   ],
   "source": [
    "# 加载 semantic function。注意目录结构\n",
    "my_skill = kernel.import_semantic_skill_from_directory(\n",
    "    \"./sk_samples/\", \"SamplePlugin\")\n",
    "\n",
    "# 运行 skill 看结果\n",
    "result = await kernel.run_async(\n",
    "        my_skill[\"GenerateCommand\"],\n",
    "        input_str=\"将系统日期设为2023-04-01\",\n",
    "    )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方提供了大量的 Semantic Functions 可以参考：https://github.com/microsoft/semantic-kernel/tree/main/samples/skills\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3、Native Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用编程语言写的函数，如果用 SK 的 Native Function 方式定义，就能纳入到 SK 的编排体系，可以被 Planner、其它 plugin 调用。\n",
    "\n",
    "下面，写一个过滤有害 Linux 命令的函数，和 GenerateCommand 组合使用。\n",
    "\n",
    "这个函数名是 `verify`。如果输入的命令不在规定范围内，就返回 `非法`，否则返回 `合法`。\n",
    "\n",
    "它可以放到目录结构中，在 [sk_samples/SamplePlugin/SamplePlugin.py](sk_samples/SamplePlugin/SamplePlugin.py) 里加入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function\n",
    "\n",
    "class CommandVerifier:\n",
    "    @sk_function(\n",
    "        description=\"检查命令是否合法\",\n",
    "        name=\"verifyCommand\",\n",
    "    )\n",
    "    def verify(self, command: str) -> str:\n",
    "        if \">\" in command:\n",
    "            return \"非法\"\n",
    "        parts = command.replace(';', '|').split('|')\n",
    "        for cmd in parts:\n",
    "            name = cmd.split(\" \")[0]\n",
    "            if name not in [\"ls\",\"cat\",\"head\",\"tail\",\"echo\"]:\n",
    "                return \"非法\"\n",
    "        return \"合法\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非法\n"
     ]
    }
   ],
   "source": [
    "# 加载 native function\n",
    "verify_skill = kernel.import_skill(CommandVerifier(), \"Verifier\")\n",
    "\n",
    "# 看结果\n",
    "result = await kernel.run_async(\n",
    "        verify_skill[\"verifyCommand\"],\n",
    "        input_str='date -s \"2023-04-01\"',\n",
    "        #input_str=\"ls -l ./\",\n",
    "    )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>在 SK 中，Semantic Function 和 Native Function 被 Kernel 平等对待。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4、用 SKContext 实现多参数 Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 Function 都只有一个参数，那么只要把参数定义为 `{{$input}}`，就可以按前面的例子来使用，比较直观。`{{$input}}`会默认被赋值。\n",
    "\n",
    "多参数时，就不能用默认机制了，需要定义 `SKContext` 类型的变量。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1、多参数 Semantic Function 的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "农夫对狼说：“你要是再来偷我的羊，我就把你变成羊！”狼回答：“那你要是再来偷我的羊，我就把你变成农夫！”\n"
     ]
    }
   ],
   "source": [
    "# Prompt 模板\n",
    "sk_prompt = \"\"\"\n",
    "讲一个{{$topic1}}和{{$topic2}}的一句话笑话\n",
    "\"\"\"\n",
    "\n",
    "# 创建 Semantic Function\n",
    "joke = kernel.create_semantic_function(sk_prompt)\n",
    "\n",
    "# 创建 SKContext\n",
    "context = kernel.create_new_context()\n",
    "\n",
    "# 变量赋值\n",
    "context[\"topic1\"] = \"农夫\"\n",
    "context[\"topic2\"] = \"狼\"\n",
    "\n",
    "# 看结果\n",
    "result = await kernel.run_async(\n",
    "    joke,\n",
    "    input_context=context\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2、多参数 Native Function 的写法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.skill_definition import sk_function, sk_function_context_parameter\n",
    "from semantic_kernel.orchestration.sk_context import SKContext\n",
    "\n",
    "class Math:\n",
    "    @sk_function(\n",
    "        description=\"加法\",\n",
    "        name=\"add\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"number1\",\n",
    "        description=\"被加数\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"number2\",\n",
    "        description=\"加数\",\n",
    "    )\n",
    "    def add(self, context: SKContext) -> str:\n",
    "        return str(float(context[\"number1\"]) + float(context[\"number2\"]))\n",
    "    \n",
    "    @sk_function(\n",
    "        description=\"减法\",\n",
    "        name=\"minus\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"number1\",\n",
    "        description=\"被减数\",\n",
    "    )\n",
    "    @sk_function_context_parameter(\n",
    "        name=\"number2\",\n",
    "        description=\"减数\",\n",
    "    )\n",
    "    def minus(self, context: SKContext) -> str:\n",
    "        return str(float(context[\"number1\"]) - float(context[\"number2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加法计算结果：66560.0\n",
      "减法计算结果：-64512.0\n"
     ]
    }
   ],
   "source": [
    "# 加载 native function\n",
    "math_skill = kernel.import_skill(Math(), \"Math\")\n",
    "\n",
    "\n",
    "# 创建 SKContext\n",
    "context = kernel.create_new_context()\n",
    "\n",
    "# 变量赋值\n",
    "context[\"number1\"] = 1024\n",
    "context[\"number2\"] = 65536\n",
    "\n",
    "# 看结果\n",
    "result = await kernel.run_async(\n",
    "    math_skill[\"add\"],\n",
    "    input_context=context\n",
    ")\n",
    "print(f\"加法计算结果：{result}\")\n",
    "\n",
    "result = await kernel.run_async(\n",
    "    math_skill[\"minus\"],\n",
    "    input_context=context\n",
    ")\n",
    "print(f\"减法计算结果：{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>在 SK 中，向函数传递多个参数，需要创建一个 SKContext 对象。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5、Plugins/Skills\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单说，plugin/skill 就是一组函数的集合。它可以包含两种函数：\n",
    "\n",
    "- Semantic Functions - 语义函数，本质是 Prompt Engineering\n",
    "- Native Functions - 原生函数，类似 OpenAI 的 Function Calling\n",
    "\n",
    "值得一提的是，SK 的 plugin 会和 ChatGPT、Bing、Microsoft 365 通用。「很快」你用 SK 写的 plugin 就可以在这些平台上无缝使用了。这些平台上的 plugin 也可以通过 SK 被你调用。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>Plugins 最初命名为 Skills，后来改为 Plugins。但是无论文档还是代码，都还有大量的「Skill」遗留，预计到 1.0.0 发布才能清理干净。见到后，就知道两者是一回事就好。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1、内置 Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 内置了若干好用的 plugin，但因为历史原因，它们叫 skill……\n",
    "\n",
    "加载方法：\n",
    "\n",
    "```python\n",
    "from semantic_kernel.core_skills import SkillName\n",
    "```\n",
    "\n",
    "它们是：\n",
    "\n",
    "- [`ConversationSummarySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/conversation_summary_skill.py) - 生成对话的摘要\n",
    "- [`FileIOSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/file_io_skill.py) - 读写文件\n",
    "- [`HttpSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/http_skill.py) - 发出 HTTP 请求，支持 GET、POST、PUT 和 DELETE\n",
    "- [`MathSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/math_skill.py) - 加法和减法计算\n",
    "- [`TextMemorySkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_memory_skill.py) - 保存文本到 memory 中，可以对其做向量检索\n",
    "- [`TextSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/text_skill.py) - 把文本全部转为大写或小写，去掉头尾的空格（trim）\n",
    "- [`TimeSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/time_skill.py) - 获取当前时间及用多种格式获取时间参数\n",
    "- [`WaitSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/wait_skill.py) - 等待指定的时间\n",
    "- [`WebSearchEngineSkill`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/web_search_engine_skill.py) - 在互联网上搜索给定的文本\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、函数调用 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 更想用 pipeline 来描述一个调用过程。跟 Langchain 的 Chain 的概念类似（下堂课讲）\n",
    "\n",
    "但是，SK 没有在代码里定义什么是 pipeline，它并不是一个类，或者函数什么的。它是贯彻整个 kernel 的一个概念。\n",
    "\n",
    "当一个 kernel 添加了 LLM、memory、functions，我们写下的 functions 之间的组合调用，就是个 pipeline 了。\n",
    "\n",
    "如果需要多条 pipeline，就定义多个 kernel。\n",
    "\n",
    "<img src=\"./picture/semantic-kernel-chains.png\" alt=\"SK 的 Pipeline\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合法\n"
     ]
    }
   ],
   "source": [
    "# 加载 semantic function。注意目录结构\n",
    "command_skill = kernel.import_semantic_skill_from_directory(\n",
    "    \"./sk_samples/\", \"SamplePlugin\"\n",
    ")\n",
    "\n",
    "# 加载 native function\n",
    "verify_skill = kernel.import_skill(CommandVerifier(), \"Verifier\")\n",
    "\n",
    "# 看结果\n",
    "result = await kernel.run_async(\n",
    "        command_skill[\"GenerateCommand\"],\n",
    "        verify_skill[\"verifyCommand\"],\n",
    "        #input_str=\"删除所有根目录文件\",\n",
    "        input_str=\"显示 example.txt 文件的内容\",\n",
    "    )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、函数的嵌套调用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1、Semantic Function 嵌套调用 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 允许在 Prompt 模板中直接调用一个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat example.txt\n"
     ]
    }
   ],
   "source": [
    "# 加载 semantic function。注意目录结构\n",
    "command_skill = kernel.import_semantic_skill_from_directory(\n",
    "    \"./sk_samples/\", \"NestedSample\"\n",
    ")\n",
    "\n",
    "# 看结果\n",
    "result = await kernel.run_async(\n",
    "        command_skill[\"GenerateCommand\"],\n",
    "        #input_str=\"删除当前目录\",\n",
    "        input_str=\"显示 example.txt 文件的内容\",\n",
    "    )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2、Native Function 嵌套调用（选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：** Native Function的嵌套调用，本质上就是函数嵌套。官方给的写法是在 Kernel 的设计思想下的实现，观感上非常晦涩。\n",
    "\n",
    "实际开发中，可以根据个人对 SK 内核与设计理念的理解，自行选择使用以下写法，或使用普通的函数调用的写法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from semantic_kernel.skill_definition import sk_function, sk_function_context_parameter\n",
    "from semantic_kernel.orchestration.sk_context import SKContext\n",
    "from semantic_kernel.orchestration.context_variables import ContextVariables\n",
    "\n",
    "class Calculator:\n",
    "    def __init__(self, kernel):\n",
    "        self._kernel = kernel # 初始化时传入 kernel\n",
    "        \n",
    "    @sk_function(\n",
    "        description=\"加减计算器\",\n",
    "        name=\"calc\",\n",
    "    )\n",
    "    async def calc(self, query: str) -> str:\n",
    "        # 嵌套调用 Semantic Function\n",
    "        q2f = self._kernel.skills.get_function(\"NestedSample\",\"Query2Function\")\n",
    "        json_str = (\n",
    "            await self._kernel.run_async(q2f, input_str=query)\n",
    "        ).result.strip()\n",
    "        json_obj = json.loads(json_str)\n",
    "        func_name = json_obj[\"name\"]\n",
    "        context = self._kernel.create_new_context()\n",
    "        context[\"number1\"] = json_obj[\"number1\"]\n",
    "        context[\"number2\"] = json_obj[\"number2\"]\n",
    "        # 嵌套调用 Native Function\n",
    "        math_func = self._kernel.skills.get_function(\"Math\",func_name)\n",
    "        result = (\n",
    "            await self._kernel.run_async(math_func, input_context=context)\n",
    "        ).result.strip()\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x7f5871cc66d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_BASE_URL')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt3\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768.0\n"
     ]
    }
   ],
   "source": [
    "# 加载 math skill\n",
    "kernel.import_skill(Math(), \"Math\")\n",
    "\n",
    "# 加载 nested skills\n",
    "kernel.import_semantic_skill_from_directory(\n",
    "    \"./sk_samples/\", \"NestedSample\")\n",
    "\n",
    "# 加载 calucator skill\n",
    "# 初始化时传入 kernel\n",
    "skill = kernel.import_skill(Calculator(kernel), \"Calculator\")\n",
    "\n",
    "result = await kernel.run_async(\n",
    "    skill[\"calc\"],\n",
    "    input_str=\"1024减去256等于多少\"\n",
    "    #input_str=\"1000加100\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、Memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 的 memory 使用非常简单：\n",
    "\n",
    "1. 用 `kernel.add_text_embedding_generation_service()` 添加一个文本向量生成服务\n",
    "2. 用 `kernel.register_memory_store()` 注册一个 memory store，可以是内存、文件、向量数据库等\n",
    "3. 用 `kernel.memory.save_information_async()` 保存信息到 memory store\n",
    "4. 用 `kernel.memory.search_async()` 搜索信息\n",
    "\n",
    "使用 ChatALL 的 README.md 做数据，使用内存作为 memory store，我们演示下基于文档对话。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1、初始化 Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x7f5871ce6910>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_BASE_URL')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-3.5-turbo\", api_key, endpoint=endpoint)\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt3\", model)\n",
    "\n",
    "# 添加 embedding 服务\n",
    "kernel.add_text_embedding_generation_service(\n",
    "    \"ada\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, endpoint=endpoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2、文本向量化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.text import split_markdown_lines\n",
    "\n",
    "# 使用内存做 memory store\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "\n",
    "# 读取文件内容\n",
    "with open('ChatALL.md', 'r') as f:\n",
    "    # with open('sk_samples/SamplePlugin/SamplePlugin.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# 将文件内容分片，单片最大 100 token（注意：SK 的 text split 功能目前对中文支持不如对英文支持得好）\n",
    "lines = split_markdown_lines(content, 100)\n",
    "\n",
    "# 将分片后的内容，存入内存\n",
    "for index, line in enumerate(lines):\n",
    "    await kernel.memory.save_information_async(\"chatall\", id=index, text=line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3、向量搜索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "拥有可以访问这些 AI 的帐号，或 API token。\n",
      "2. 与 AI 网站有可靠的网络连接。\n",
      "\n",
      "## 下载 / 安装\n",
      "\n",
      "从 https://github.com/sunner/ChatALL/releases 下载\n",
      "\n",
      "### Windows 系统\n",
      "\n",
      "直接下载 \\*-win.exe 安装文件并运行之。\n",
      "\n",
      "### macOS 系统\n",
      "\n",
      "对于苹果硅芯片 Mac（M1，M2 CPU），请下载 \\*-mac-arm64.\n"
     ]
    }
   ],
   "source": [
    "result = await kernel.memory.search_async(\"chatall\", \"ChatALL怎么下载？\")\n",
    "print(result[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4、现在用函数嵌套做一个简单的 RAG\n",
    "\n",
    "例：基于 ChatALL 的说明文档，做问答\n",
    "\n",
    "在自定义的 Semantic Function 中，嵌套调用内置的 `TextMemorySkill`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 https://github.com/sunner/ChatALL/releases 下载安装文件。对于Windows系统，下载\\*-win.exe文件并运行；对于苹果硅芯片Mac系统，请下载\\*-mac-arm64文件。\n"
     ]
    }
   ],
   "source": [
    "# 导入内置的 `TextMemorySkill`。主要使用它的 `recall()`\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
    "\n",
    "# 直接在代码里创建 semantic function。真实工程不建议这么做\n",
    "# 里面调用了 `recall()`\n",
    "sk_prompt = \"\"\"\n",
    "基于下面的背景信息回答问题。如果背景信息为空，或者和问题不相关，请回答\"我不知道\"。\n",
    "\n",
    "[背景信息开始]\n",
    "{{recall $input}}\n",
    "[背景信息结束]\n",
    "\n",
    "问题：{{$input}}\n",
    "回答：\n",
    "\"\"\"\n",
    "ask = kernel.create_semantic_function(sk_prompt)\n",
    "\n",
    "# 提问\n",
    "context = kernel.create_new_context()\n",
    "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = \"chatall\" # The collection to search for information\n",
    "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8 # The relevance score, from 0.0 to 1.0; 1.0 means perfect match\n",
    "context[\"input\"] = \"ChatALL 怎么下载？\"\n",
    "\n",
    "result = await kernel.run_async(\n",
    "    ask,\n",
    "    input_context=context,\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5、连接其它 VectorDB\n",
    "\n",
    "Semantic Kernel目前已与很多主流的向量数据库做了适配\n",
    "\n",
    "具体参考：https://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK 的 Planner 目的是 Agent 开发。只封装了几个基本形式，把更多的探索留给了开发者。\n",
    "\n",
    "### 7.1、什么是智能体（Agent）\n",
    "\n",
    "将大语言模型作为一个推理引擎。给定一个任务，智能体自动生成完成任务所需的步骤，执行相应动作（例如选择并调用工具），直到任务完成。\n",
    "\n",
    "这个多步骤的规划过程，就由 **Planner** 完成。\n",
    "\n",
    "<img src=\"./picture/agent-overview.png\" style=\"margin-left: 0px\" width=500px>\n",
    "\n",
    "### 7.2、SK Python 提供了四种 Planner：\n",
    "\n",
    "1. `SequentialPlanner`\n",
    "   - 制定包含一系列步骤的计划，这些步骤通过自定义生成的输入和输出变量相互连接\n",
    "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/sequential_planner/Skills/SequentialPlanning/skprompt.txt\n",
    "   - 官方例程：https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py\n",
    "2. `ActionPlanner`\n",
    "   - 类似 OpenAI Function Calling，从 kernel 中已注册的所有 plugin 中找到一个该执行的函数\n",
    "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/action_planner/skprompt.txt\n",
    "   - 官方例程：https://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py\n",
    "3. `StepwisePlanner`\n",
    "   - 每执行完一步，都做一下复盘\n",
    "   - 只输出 action，不执行\n",
    "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/stepwise_planner/Skills/StepwiseStep/skprompt.txt\n",
    "4. `BasicPlanner`\n",
    "   - **不建议使用**。把任务拆解，自动调用各个函数，完成任务。它只是个用于基础验证的功能，最终会被 `SequentialPlanner` 替代\n",
    "   - 核心 prompt：https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planning/basic_planner.py#L27-L123\n",
    "\n",
    "使用 planner 的步骤非常简单：\n",
    "\n",
    "1. 把 plugin 注册到 kernel\n",
    "2. 把 kernel 当参数实例化某个 planner\n",
    "3. 调用 planner 的 `create_plan_async()` 方法获得 plan\n",
    "4. 调用 plan 的 `invoke_async()` 方法执行 plan\n",
    "\n",
    "(注意，不同 planner 接口并不一致，不能简单平替)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3、用 Planner 实现一个能使用搜索和日历工具的 Agent\n",
    "\n",
    "例：周杰伦的生日是星期几"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.kernel.Kernel at 0x7f58b3c22710>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.core_skills import WebSearchEngineSkill\n",
    "from semantic_kernel.connectors.search_engine import BingConnector\n",
    "from semantic_kernel.planning import SequentialPlanner\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "import os\n",
    "\n",
    "# 加载 .env 到环境变量\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 创建 semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# 配置 OpenAI 服务\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "endpoint = os.getenv('OPENAI_BASE_URL')\n",
    "model = OpenAIChatCompletion(\n",
    "    \"gpt-4\", api_key, endpoint=endpoint)\n",
    "\n",
    "# 把 LLM 服务加入 kernel\n",
    "# 可以加多个。第一个加入的会被默认使用，非默认的要被指定使用\n",
    "kernel.add_text_completion_service(\"my-gpt4\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import dateutil.parser as parser\n",
    "from datetime import date\n",
    "\n",
    "class DayOfWeek:\n",
    "    @sk_function(\n",
    "        description=\"计算输入日期是星期几\",\n",
    "        name=\"weekday\",\n",
    "    )\n",
    "    def weekday(self, date_str: str) -> str:\n",
    "        \"\"\"Convert date to weekday name\"\"\"\n",
    "        d = parser.parse(date_str)\n",
    "        return calendar.day_name[d.weekday()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<semantic_kernel.orchestration.sk_function.SKFunction at 0x7f5871cc6550>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "抽取下述文本中第一个出现的日期。\n",
    "以YYYY-MM-DD格式输出。\n",
    "\n",
    "{{$input}}\n",
    "\"\"\"\n",
    "kernel.create_semantic_function(\n",
    "    sk_prompt, \n",
    "    function_name=\"parseDate\",\n",
    "    skill_name=\"DateParser\",\n",
    "    description=\"抽取输入文本中的日期\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weekday': <semantic_kernel.orchestration.sk_function.SKFunction at 0x7f5871ce7e10>}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入搜索 plugin\n",
    "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
    "kernel.import_skill(WebSearchEngineSkill(connector), \"WebSearch\")\n",
    "\n",
    "kernel.import_skill(\n",
    "    DayOfWeek(), \"DayOfWeek\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Description: Performs a web search for a given query\n",
      "Function: WebSearch.searchAsync\n",
      "  Output:\n",
      " ['周杰伦（Jay Chou），1979年1月18日出生于台湾省新北市，祖籍福建省泉州市永春县，中国台湾流行乐男歌手、音乐人、演员、导演、编剧，毕业于淡江中学。2000年发行个人首张专辑《Jay》。2001年发行的专辑《范特西》奠定其融合中西方音乐的风格。2002年举行“The One”世界巡回演唱会。']\n",
      "Step: 1\n",
      "Description: 抽取输入文本中的日期\n",
      "Function: DateParser.parseDate\n",
      "  Output:\n",
      " 1979-01-18\n",
      "Step: 2\n",
      "Description: 计算输入日期是星期几\n",
      "Function: DayOfWeek.weekday\n",
      "  Output:\n",
      " Thursday\n",
      "Thursday\n"
     ]
    }
   ],
   "source": [
    "# 创建 planner\n",
    "planner = SequentialPlanner(kernel)\n",
    "\n",
    "# 开始\n",
    "query = \"周杰伦的生日是星期几？\"\n",
    "plan = await planner.create_plan_async(goal=query)\n",
    "\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "# 打印步骤用来调试\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(\"Step:\", index)\n",
    "    print(\"Description:\", step.description)\n",
    "    print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "    if len(step._outputs) > 0:\n",
    "        print(\"  Output:\\n\", str.replace(\n",
    "            result[step._outputs[0]], \"\\n\", \"\\n  \"))\n",
    "\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8、VS Code 插件\n",
    "\n",
    "这是个 VS Code 的插件，在 VS Code 里可以直接创建和调试 Semantic Function。\n",
    "\n",
    "安装地址：https://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9、Semantic Kernel 对新版 Assistants API 的支持计划\n",
    "\n",
    "当前进展：\n",
    "  - C#版实验性支持：https://github.com/microsoft/semantic-kernel/releases\n",
    "\n",
    "虽然 Assistants API 原生的管理了一切\n",
    "\n",
    "但官方宣称，Semantic Kernel 将在以下方面提供附加价值：\n",
    "\n",
    "1. 简化的 Function Calling（本质是将 function 调用和结果回传封装在 pipeline 中）\n",
    "2. 实现更复杂的多步 plan（条件分支、循环、变量传递等）\n",
    "3. 多 LLM 整合，例如GPT-3.5用于简单功能、GPT-4用于最终回复等\n",
    "4. 更可控（自定义）的 Memory 引擎\n",
    "5. 更多的可视化及监控机制\n",
    "\n",
    "原文：https://devblogs.microsoft.com/semantic-kernel/assistants-the-future-of-semantic-kernel/\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b>1-4本质就是自定义的过程的封装，由此再次体会 SDK 的价值\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
