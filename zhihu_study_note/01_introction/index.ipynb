{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 大模型应用开发基础\n",
    "\n",
    "## 主要内容\n",
    "1. 了解大模型都能做什么\n",
    "2. 整体了解大模型应用开发技术栈\n",
    "3. 浅尝 OpenAI API 的调用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、知识体系\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/structure.png\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 二、什么是 AI？\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/ai-timeline.png\" style=\"margin-left: 0px\" width=\"800px\">\n",
    "\n",
    "> 「深蓝」的创造者许峰雄博士说过：「AI is bullshit。深蓝没用任何 AI 算法，就是硬件穷举棋步。」\n",
    "\n",
    "一种观点：基于机器学习、神经网络的是 AI，基于规则、搜索的不是 AI。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 三、大模型能干什么？\n",
    "\n",
    "大模型，全称「大语言模型」，英文「Large Language Model」，缩写「LLM」。\n",
    "\n",
    "现在，已经不需要再演示了。每人应该都至少和下面一个大模型 AI 对话过至少 100 次。\n",
    "\n",
    "- ChatGPT：[https://chat.openai.com/](https://chat.openai.com/)\n",
    "- Bing Chat：[https://bing.com/new](https://bing.com/new)\n",
    "- 文心一言：[https://yiyan.baidu.com/](https://yiyan.baidu.com/)\n",
    "- 讯飞星火：[https://xinghuo.xfyun.cn/](https://xinghuo.xfyun.cn/)\n",
    "- 智谱清言：[https://chatglm.cn/](https://chatglm.cn/)\n",
    "\n",
    "但是，千万别以为大模型只是聊天机器人。它的应用场景，远不止于此。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "### 3.1、按格式输出\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/gpt-ner.png\" style=\"margin-left: 0px\">\n",
    "\n",
    "### 3.2、分类\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/gpt-classification.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 3.3、聚类\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/gpt-clustering.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 3.4、持续互动\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/gpt-decision.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 3.5、技术相关问题\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/gpt-plan.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "### 3.6、更多举例\n",
    "\n",
    "- **舆情分析：**从公司产品的评论中，分析哪些功能/元素是用户讨论最多的，评价是正向还是负向\n",
    "- **坐席质检：**检查客服/销售人员与用户的对话记录，判断是否有争吵、辱骂、不当言论，话术是否符合标准\n",
    "- **故障解释：**根据系统报错信息，给出方便非技术人员阅读的故障说明\n",
    "- **零代码开发/运维：**自动规划任务，生成指令，自动执行\n",
    "- **生成业务逻辑：**自定义一套业务描述语言（DSL），直接让 ChatGPT 写业务逻辑代码\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "### 3.7、可能一切问题，都能解决，所以是 AGI\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "<ol>\n",
    "<li>把 ChatGPT 看做是一个函数，给输入，<b>生成</b>输出</li>\n",
    "<li>任何业务问题，都可以用语言描述，成为 ChatGPT 的输入，就能<b>生成</b>业务问题的结果</li>\n",
    "<li>实际工作中，通常需要将业务任务拆解为若干个子任务，分别解决。<b>理解问题本质，对拆解任务有很大帮助！</b></li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "这是美好的理想，现在还远不能做到\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 四、大模型是怎么生成结果的？\n",
    "\n",
    "其实，它只是根据上文，猜下一个词（的概率）…… 这个算法叫 transformer\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/lm-autoregressive.gif\" style=\"margin-left: 0px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "OpenAI 的接口名就叫「completion」，也证明了其只会「生成」的本质。\n",
    "\n",
    "下面用程序演示「生成下一个字」。你可以自己修改 prompt 试试。还可以使用相同的 prompt 运行多次。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高兴，因为我学会了如何使用github\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "prompt = \"今天我很\"\n",
    "response = openai.Completion.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    temperature=0,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>\n",
    "我们用不严密但通俗的语言描述 ChatGPT 的工作原理：\n",
    "<ol>\n",
    "<li>GPT「大模型」阅读了人类曾说过的所有的话。这就是「学习」</li>\n",
    "<li>把一串 token 后面跟着的不同 token 的<b>概率</b>记下来。记下的就是「参数」，也叫「权重」</li>\n",
    "<li>当我们给它若干 token，GPT 就能算出概率最高的下一个 token 是什么。这就是「生成」</li>\n",
    "<li>用生成的 token，再加上上文，就能继续生成下一个 token。以此类推，生成更多文字</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "Token 是什么？\n",
    "\n",
    "1. 可能是一个英文单词，也可能是半个，三分之一个。可能是一个中文词，或者一个汉字，也可能是半个汉字，甚至三分之一个汉字\n",
    "2. 大模型在开训前，需要先训练一个 tokenizer 模型。它能把所有的文本，切成 token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、用好 AI 的核心心法\n",
    "\n",
    "OpenAI 首席科学家 Ilya Sutskever 说过：数字神经网络和人脑的生物神经网络，在数学原理上是一样的。\n",
    "\n",
    "所以，我们要：\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "把 AI 当人看。<br>\n",
    "把 AI 当人看。<br>\n",
    "把 AI 当人看。\n",
    "</div>\n",
    "\n",
    "我们和凯文·凯利交流时，他说了类似的观点：「和人怎么相处，就和 AI 怎么相处。」\n",
    "\n",
    "1. 用「当人看」来理解 AI\n",
    "2. 用「当人看」来控制 AI\n",
    "3. 用「当人看」来说服用户正确看待 AI 的不足\n",
    "\n",
    "这是贯彻整门课，甚至我们与 AI 为伴的整个生涯的心法。现在不认同、不理解都没关系，慢慢来。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 六、大模型应用架构\n",
    "\n",
    "大模型技术分两个部分：\n",
    "\n",
    "1. **训练基础大模型**：全世界只需要 1000 人做这个\n",
    "2. **建造大模型应用**：所有技术人都需要掌握\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "大模型应用技术特点：<strong>门槛低，落地难。</strong>\n",
    "</div>\n",
    "\n",
    "像极了做管理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1、典型业务架构\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/business_arch.webp\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "Agent 还太超前，Copilot 值得追求。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2、技术架构\n",
    "\n",
    "#### 纯 Prompt\n",
    "\n",
    "就像和一个人对话，你说一句，ta 回一句，你再说一句，ta 再回一句……\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/prompt_arch.png\" style=\"margin-left: 0px\" width=300px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent + Function Calling\n",
    "\n",
    "- Agent：AI 主动提要求\n",
    "- Function Calling：AI 要求执行某个函数\n",
    "- 场景举例：你问过年去哪玩，ta 先反问你有几天假\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/func_arch.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings + 向量数据库\n",
    "\n",
    "- Embeddings：把文字转换为更易于相似度计算的编码。这种编码叫向量\n",
    "- 向量数据库：把向量存起来，方便查找\n",
    "- 向量搜索：根据输入向量，找到最相似的向量\n",
    "- 场景举例：考试时，看到一道题，到书上找相关内容，再结合题目组成答案。然后，就都忘了\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/embeddings_arch.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tuning\n",
    "\n",
    "努力学习考试内容，长期记住，活学活用。\n",
    "\n",
    "<img src=\"/Users/huangxinzhe/code/llm_note/zhihu_study_note/01_introction/picture/tech_arch.png\" style=\"margin-left: 0px\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nOf4rvQ13si"
   },
   "source": [
    "## 七、OpenAI API 初探\n",
    "\n",
    "### 7.1、安装 Python 库\n",
    "\n",
    "```bash\n",
    "pip install --upgrade openai\n",
    "```\n",
    "\n",
    "### 7.2、查看可调用的模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-search-babbage-doc-001\n",
      "gpt-3.5-turbo-16k-0613\n",
      "curie-search-query\n",
      "gpt-3.5-turbo-16k\n",
      "text-search-babbage-query-001\n",
      "babbage\n",
      "babbage-search-query\n",
      "text-babbage-001\n",
      "whisper-1\n",
      "text-similarity-davinci-001\n",
      "davinci-similarity\n",
      "code-davinci-edit-001\n",
      "curie-similarity\n",
      "babbage-search-document\n",
      "curie-instruct-beta\n",
      "text-search-ada-doc-001\n",
      "davinci-instruct-beta\n",
      "gpt-3.5-turbo-0613\n",
      "text-similarity-babbage-001\n",
      "text-search-davinci-doc-001\n",
      "gpt-4-0314\n",
      "gpt-4-0613\n",
      "gpt-4\n",
      "babbage-similarity\n",
      "text-embedding-ada-002\n",
      "davinci-search-query\n",
      "text-similarity-curie-001\n",
      "text-davinci-001\n",
      "text-search-davinci-query-001\n",
      "ada-search-document\n",
      "ada-code-search-code\n",
      "babbage-002\n",
      "davinci-002\n",
      "davinci-search-document\n",
      "curie-search-document\n",
      "babbage-code-search-code\n",
      "text-search-ada-query-001\n",
      "code-search-ada-text-001\n",
      "babbage-code-search-text\n",
      "code-search-babbage-code-001\n",
      "ada-search-query\n",
      "ada-code-search-text\n",
      "text-search-curie-query-001\n",
      "text-davinci-002\n",
      "text-davinci-edit-001\n",
      "code-search-babbage-text-001\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "ada\n",
      "text-ada-001\n",
      "ada-similarity\n",
      "code-search-ada-code-001\n",
      "text-similarity-ada-001\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-instruct\n",
      "text-search-curie-doc-001\n",
      "text-davinci-003\n",
      "text-curie-001\n",
      "curie\n",
      "davinci\n",
      "davinci:ft-personal:100qa-2023-03-06-07-35-38\n",
      "ft:gpt-3.5-turbo-0613:agi-class::7rFIG3Mf\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# 加载 .env 文件\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 从环境变量中获得你的 OpenAI Key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# 模型列表\n",
    "models = openai.Model.list()\n",
    "\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3、发一条消息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是AI助手小瓜，我负责回答关于AGIClass课程的问题。课程每周二、四上课。如果你有任何关于课程的问题，都可以随时向我提问。\n"
     ]
    }
   ],
   "source": [
    "# 消息格式\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"你是AI助手小瓜.你是AGIClass的助教。这门课每周二、四上课。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你是干什么的?什么时间上课\"\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "# 调用ChatGPT-3.5\n",
    "chat_completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\", messages=messages)\n",
    "\n",
    "# 输出回复\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
